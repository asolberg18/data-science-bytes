{
 "metadata": {
  "name": "",
  "signature": "sha256:dd14101a279ebacc1de5f7db498895019be5421906f625e4997bdb2b46b833cc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this post I extract all the words spoken by each character in eight of Shakespeare's plays. Then I construct a topic model to see which characters are generally speaking about similar things. In [Part II](http://www.datasciencebytes.com/bytes/2014/12/31/analysis-of-shakespeare-characters-speech-topics/) I look into the information revealed by the topic model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import pandas as pd\n",
      "from collections import defaultdict\n",
      "from gensim import corpora, models, similarities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The nltk library includes eight of Skakespeare's plays in xml format, which makes it easy to split up line by speaker. [Here's an example of the xml format](http://www.ibiblio.org/xml/examples/shakespeare/hamlet.xml)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.corpus.shakespeare.fileids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "['a_and_c.xml',\n",
        " 'dream.xml',\n",
        " 'hamlet.xml',\n",
        " 'j_caesar.xml',\n",
        " 'macbeth.xml',\n",
        " 'merchant.xml',\n",
        " 'othello.xml',\n",
        " 'r_and_j.xml']"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`parse_plays` returns two dictionaries, mapping each speaker in each play to the words they say and the number of lines they have."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_plays(file_ids, \n",
      "                tokenizer=nltk.tokenize.RegexpTokenizer(r'\\w+'),\n",
      "                stopwords=set(nltk.corpus.stopwords.words('english'))):\n",
      "    \"\"\"Return two dictionaries, mapping each speaker in each play to the \n",
      "    words they say and the number of lines they have.\n",
      "    \n",
      "    :param file_ids: the nltk file_ids of play xml files\n",
      "    :param tokenizer: tokenizer to split words within the lines\n",
      "      default: nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
      "    :param stopwords: set of words to exclude\n",
      "      default: set(nltk.corpus.stopwords.words('english'))\n",
      "    \"\"\"\n",
      "    lines = defaultdict(list)\n",
      "    linecounts = defaultdict(int)\n",
      "    for file_id in file_ids:\n",
      "        raw_data = nltk.corpus.shakespeare.xml(file_id)\n",
      "        for child in raw_data.findall('ACT/SCENE/SPEECH'):\n",
      "            speaker = (child.find('SPEAKER').text, file_id.replace('.xml', ''))\n",
      "            for line in child.findall('LINE'):\n",
      "                if line.text is not None:\n",
      "                    for word in tokenizer.tokenize(line.text):\n",
      "                        word_lower = word.lower()\n",
      "                        if word_lower not in stopwords and len(word) > 2:\n",
      "                            lines[speaker].append(word_lower)\n",
      "                            linecounts[speaker] += 1\n",
      "    return lines, linecounts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To make the cleanup and manipulation of data easier, I put the relevent data into a pandas DataFrame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_lines = 100\n",
      "lines, linecounts = parse_plays(nltk.corpus.shakespeare.fileids())\n",
      "word_data = [(speaker[0], speaker[1], count, lines[speaker]) \n",
      "             for speaker, count in linecounts.iteritems()\n",
      "             if count >= min_lines]\n",
      "word_data_df = pd.DataFrame(word_data, columns=['persona', 'play', 'linecount', 'words'])\n",
      "word_data_df = word_data_df.sort('linecount', ascending=False).reset_index(drop=True)\n",
      "word_data_df.ix[:, :3].to_csv('data/word_data_df.csv')\n",
      "word_data_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>persona</th>\n",
        "      <th>play</th>\n",
        "      <th>linecount</th>\n",
        "      <th>words</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>      HAMLET</td>\n",
        "      <td>  hamlet</td>\n",
        "      <td> 5461</td>\n",
        "      <td> [lord, much, sun, madam, common, seems, madam,...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>        IAGO</td>\n",
        "      <td> othello</td>\n",
        "      <td> 3857</td>\n",
        "      <td> [sblood, hear, ever, dream, matter, abhor, des...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>     OTHELLO</td>\n",
        "      <td> othello</td>\n",
        "      <td> 3059</td>\n",
        "      <td> [tis, better, let, spite, services, done, sign...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> MARK ANTONY</td>\n",
        "      <td> a_and_c</td>\n",
        "      <td> 2984</td>\n",
        "      <td> [beggary, love, reckon, must, thou, needs, fin...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>     MACBETH</td>\n",
        "      <td> macbeth</td>\n",
        "      <td> 2653</td>\n",
        "      <td> [foul, fair, day, seen, speak, stay, imperfect...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "       persona     play  linecount  \\\n",
        "0       HAMLET   hamlet       5461   \n",
        "1         IAGO  othello       3857   \n",
        "2      OTHELLO  othello       3059   \n",
        "3  MARK ANTONY  a_and_c       2984   \n",
        "4      MACBETH  macbeth       2653   \n",
        "\n",
        "                                               words  \n",
        "0  [lord, much, sun, madam, common, seems, madam,...  \n",
        "1  [sblood, hear, ever, dream, matter, abhor, des...  \n",
        "2  [tis, better, let, spite, services, done, sign...  \n",
        "3  [beggary, love, reckon, must, thou, needs, fin...  \n",
        "4  [foul, fair, day, seen, speak, stay, imperfect...  "
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here I make a gensim dictionary, which creates a mapping of words to integer ids. The integer ids are used by gensim in the later steps to extract a topic model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "line_list = word_data_df['words'].values\n",
      "dictionary = corpora.Dictionary(line_list)\n",
      "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq == 1]\n",
      "dictionary.filter_tokens(once_ids)\n",
      "dictionary.compactify()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The below step creates a sparse vector of integer words ids to word counts for each character and a [TF-IDF](http://en.wikipedia.org/wiki/Tf%E2%80%93idf) model. The TF-IDF model converts raw word counts to a value more indicative of the importance of each word."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [dictionary.doc2bow(words) for words in line_list]\n",
      "corpora.mmcorpus.MmCorpus.serialize('data/shkspr.mm', corpus)\n",
      "tfidf = models.TfidfModel(corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, the model is constructed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi = models.lsimodel.LsiModel(corpus=tfidf[corpus], id2word=dictionary)\n",
      "lsi.save('data/shkspr.lsi')\n",
      "for i, topic in enumerate(lsi.print_topics(5)[:3]):\n",
      "    print 'Topic {}:'.format(i)\n",
      "    print topic.replace(' + ', '\\n')\n",
      "    print ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Topic 0:\n",
        "0.192*\"caesar\"\n",
        "0.125*\"lord\"\n",
        "0.121*\"antony\"\n",
        "0.112*\"brutus\"\n",
        "0.106*\"thou\"\n",
        "0.105*\"romeo\"\n",
        "0.093*\"cassio\"\n",
        "0.091*\"love\"\n",
        "0.084*\"thee\"\n",
        "0.078*\"madam\"\n",
        "\n",
        "Topic 1:\n",
        "0.513*\"caesar\"\n",
        "0.378*\"brutus\"\n",
        "0.286*\"antony\"\n",
        "0.192*\"cassius\"\n",
        "-0.151*\"romeo\"\n",
        "0.139*\"rome\"\n",
        "-0.108*\"cassio\"\n",
        "0.090*\"octavius\"\n",
        "0.081*\"lepidus\"\n",
        "-0.073*\"tybalt\"\n",
        "\n",
        "Topic 2:\n",
        "0.460*\"cassio\"\n",
        "-0.351*\"romeo\"\n",
        "-0.170*\"tybalt\"\n",
        "0.164*\"iago\"\n",
        "0.163*\"moor\"\n",
        "-0.125*\"juliet\"\n",
        "-0.115*\"nurse\"\n",
        "0.110*\"desdemona\"\n",
        "0.105*\"lord\"\n",
        "0.104*\"lieutenant\"\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The topic model is now constructed. In [Part II](http://www.datasciencebytes.com/bytes/2014/12/31/analysis-of-shakespeare-characters-speech-topics/) I'll analyze the results."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}