{
 "metadata": {
  "name": "",
  "signature": "sha256:39b344c7e4d139f94b0823f10d3426f1505fa35a7809a035e75a902741023e70"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this post I extract all the words spoken by each character in eight of Shakespeare's plays. Then I construct a topic model to see which characters are generally speaking about similar things. In [Part II]() I look into the information revealed by the topic model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import pandas as pd\n",
      "from collections import defaultdict\n",
      "from gensim import corpora, models, similarities"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The nltk library includes eight of Skakespeare's plays in xml format, which makes it easy to split up line by speaker. [Here's an example of the xml format](http://www.ibiblio.org/xml/examples/shakespeare/hamlet.xml)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.corpus.shakespeare.fileids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['a_and_c.xml', 'dream.xml', 'hamlet.xml', 'j_caesar.xml', 'macbeth.xml', 'merchant.xml', 'othello.xml', 'r_and_j.xml']\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`parse_plays` returns two dictionaries, mapping each speaker in each play to the words they say and the number of lines they have."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_plays(file_ids, \n",
      "                tokenizer=nltk.tokenize.RegexpTokenizer(r'\\w+'),\n",
      "                stopwords=set(nltk.corpus.stopwords.words('english'))):\n",
      "    \"\"\"Return two dictionaries, mapping each speaker in each play to the \n",
      "    words they say and the number of lines they have.\n",
      "    \n",
      "    :param file_ids: the nltk file_ids of play xml files\n",
      "    :param tokenizer: tokenizer to split words within the lines\n",
      "      default: nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
      "    :param stopwords: set of words to exclude\n",
      "      default: set(nltk.corpus.stopwords.words('english'))\n",
      "    \"\"\"\n",
      "    lines = defaultdict(list)\n",
      "    linecounts = defaultdict(int)\n",
      "    for file_id in file_ids:\n",
      "        raw_data = nltk.corpus.shakespeare.xml(file_id)\n",
      "        for child in raw_data.findall('ACT/SCENE/SPEECH'):\n",
      "            speaker = (child.find('SPEAKER').text, file_id.replace('.xml', ''))\n",
      "            for line in child.findall('LINE'):\n",
      "                if line.text is not None:\n",
      "                    for word in tokenizer.tokenize(line.text):\n",
      "                        word_lower = word.lower()\n",
      "                        if word_lower not in stopwords and len(word) > 2:\n",
      "                            lines[speaker].append(word_lower)\n",
      "                            linecounts[speaker] += 1\n",
      "    return lines, linecounts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_lines = 100\n",
      "lines, linecounts = parse_plays(nltk.corpus.shakespeare.fileids())\n",
      "word_data = [(speaker[0], speaker[1], count, lines[speaker]) \n",
      "             for speaker, count in linecounts.iteritems()\n",
      "             if count >= min_lines]\n",
      "word_data_df = pd.DataFrame(word_data, columns=['persona', 'play', 'linecount', 'words'])\n",
      "word_data_df = word_data_df.sort('linecount', ascending=False).reset_index(drop=True)\n",
      "personae = linecount_df[linecount_df['linecount'] > min_lines]['persona'].values\n",
      "word_data_df.ix[:, :3].to_csv('data/word_data_df.csv')\n",
      "word_data_df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>persona</th>\n",
        "      <th>play</th>\n",
        "      <th>linecount</th>\n",
        "      <th>words</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>      HAMLET</td>\n",
        "      <td>  hamlet</td>\n",
        "      <td> 5461</td>\n",
        "      <td> [lord, much, sun, madam, common, seems, madam,...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>        IAGO</td>\n",
        "      <td> othello</td>\n",
        "      <td> 3857</td>\n",
        "      <td> [sblood, hear, ever, dream, matter, abhor, des...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>     OTHELLO</td>\n",
        "      <td> othello</td>\n",
        "      <td> 3059</td>\n",
        "      <td> [tis, better, let, spite, services, done, sign...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> MARK ANTONY</td>\n",
        "      <td> a_and_c</td>\n",
        "      <td> 2984</td>\n",
        "      <td> [beggary, love, reckon, must, thou, needs, fin...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>     MACBETH</td>\n",
        "      <td> macbeth</td>\n",
        "      <td> 2653</td>\n",
        "      <td> [foul, fair, day, seen, speak, stay, imperfect...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 167,
       "text": [
        "       persona     play  linecount  \\\n",
        "0       HAMLET   hamlet       5461   \n",
        "1         IAGO  othello       3857   \n",
        "2      OTHELLO  othello       3059   \n",
        "3  MARK ANTONY  a_and_c       2984   \n",
        "4      MACBETH  macbeth       2653   \n",
        "\n",
        "                                               words  \n",
        "0  [lord, much, sun, madam, common, seems, madam,...  \n",
        "1  [sblood, hear, ever, dream, matter, abhor, des...  \n",
        "2  [tis, better, let, spite, services, done, sign...  \n",
        "3  [beggary, love, reckon, must, thou, needs, fin...  \n",
        "4  [foul, fair, day, seen, speak, stay, imperfect...  "
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here I make a gensim dictionary to which creates a mapping of words to integer ids. The integer ids are used by gensim in the later steps to extract a topic model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "line_list = word_data_df['words'].values\n",
      "dictionary = corpora.Dictionary(line_list)\n",
      "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq == 1]\n",
      "dictionary.filter_tokens(once_ids)\n",
      "dictionary.compactify()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 151
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The below step creates a sparse vector of words ids to word counts for each character and a TF-IDF model. The TF-IDF model converts raw word counts to a value more indicative of the importance of each word."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [dictionary.doc2bow(words) for words in line_list]\n",
      "corpora.mmcorpus.MmCorpus.serialize('data/shkspr.mm', corpus)\n",
      "tfidf = models.TfidfModel(corpus)\n",
      "tfidf_corpus = tfidf[corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, the model is constructed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lsi = models.lsimodel.LsiModel(corpus=tfidf_corpus, id2word=dictionary)\n",
      "lsi.save('data/shkspr.lsi')\n",
      "lsi.print_topics(5)[:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "[u'0.192*\"caesar\" + 0.125*\"lord\" + 0.121*\"antony\" + 0.112*\"brutus\" + 0.106*\"thou\" + 0.105*\"romeo\" + 0.093*\"cassio\" + 0.091*\"love\" + 0.084*\"thee\" + 0.078*\"madam\"',\n",
        " u'0.513*\"caesar\" + 0.378*\"brutus\" + 0.286*\"antony\" + 0.192*\"cassius\" + -0.151*\"romeo\" + 0.139*\"rome\" + -0.108*\"cassio\" + 0.090*\"octavius\" + 0.081*\"lepidus\" + -0.073*\"tybalt\"',\n",
        " u'0.460*\"cassio\" + -0.351*\"romeo\" + -0.170*\"tybalt\" + 0.164*\"iago\" + 0.163*\"moor\" + -0.125*\"juliet\" + -0.115*\"nurse\" + 0.110*\"desdemona\" + 0.105*\"lord\" + 0.104*\"lieutenant\"']"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With the model constructed, in [Part II]() I'll analyze the results."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}