{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates and times provide an unlimited source of hassles for anyone working with them. In this post I'll discuss a potential performance pitfall I encountered parsing dates in pandas. **Conclusion: Create DatetimeIndices by parsing data with `to_datetime(my_dates, format='my_format')`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get some data to test on, I create a list of dictionaries with strings representing a datetime and an observed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timestamp': '10/12/98 18:03', 'value': 0.49671415301123267}\n"
     ]
    }
   ],
   "source": [
    "# Generate some fake timestamped data\n",
    "num_rows = int(1e6)\n",
    "np.random.seed(42)\n",
    "data = np.random.randn(num_rows)\n",
    "records = []\n",
    "for i in xrange(num_rows):\n",
    "    timestamp = np.random.randint(0, int(time.time()))\n",
    "    date_string = datetime.fromtimestamp(timestamp).strftime('%m/%d/%y %H:%M')\n",
    "    records.append({'timestamp': date_string, 'value': data[i]})\n",
    "    \n",
    "print records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'll parse the random data into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10/12/98 18:03</th>\n",
       "      <td> 0.496714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11/16/88 08:49</th>\n",
       "      <td>-0.138264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/21/78 21:13</th>\n",
       "      <td> 0.647689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   value\n",
       "timestamp               \n",
       "10/12/98 18:03  0.496714\n",
       "11/16/88 08:49 -0.138264\n",
       "03/21/78 21:13  0.647689"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(records).set_index('timestamp')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "\n",
    "I want to create a datetime index so I can calculate the sum of each value by day. Here are two different methods with very different performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1:** Use the `DatetimeIndex` constructor on the strings (very slow!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 2min 31s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_dt_constructor = df.copy()\n",
    "df_dt_constructor.index = pd.DatetimeIndex(df_dt_constructor.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2:** Parse the datetimes using `to_datetime` and assign the index (much faster!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 4.79 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_parse_with_format = df.copy()\n",
    "df_parse_with_format.index = pd.to_datetime(df_parse_with_format.index, \n",
    "                                            format='%m/%d/%y %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By parsing the dates with `to_datetime` the operation runs about 30x faster. If a format argument isn't supplied `to_datetime` it is still faster than calling the `DatetimeIndex` constructor directly, however only by about 2x. This can be beneficial since `to_datetime` can handle data with inconsistent date formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 3:** Parse without format (flexible but slow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1min 27s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "df_parse_no_format = df.copy()\n",
    "df_parse_no_format.index = pd.to_datetime(df_parse_no_format.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas makes it easy to aggregate the data into different time periods. This code computes the sum of the values for each day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_parse_first = df.copy()\n",
    "df_parse_first.index = pd.to_datetime(df_parse_first.index,\n",
    "                                      format='%m/%d/%y %H:%M')\n",
    "daily_sum = df_parse_first.resample('D', how='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we collapsed many records into few we can still learn some things about the original data set. For example, we expect the variance of the daily sums to be the number of values in each bucket (because the underlying data was random normal). Using this the number of total observations can be estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated there were 998,176.47 original records\n",
      "Error: -0.18%\n"
     ]
    }
   ],
   "source": [
    "variance = daily_sum.var()[0]\n",
    "num_days = len(daily_sum)\n",
    "est_num_original_records = variance * num_days\n",
    "error_pct = 100 * (est_num_original_records - num_rows) / num_rows\n",
    "print 'Estimated there were {:,.2f} original records'.format(est_num_original_records)\n",
    "print 'Error: {0:.2f}%'.format(error_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
